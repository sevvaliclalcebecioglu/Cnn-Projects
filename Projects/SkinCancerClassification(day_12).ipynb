{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b88dc65f-55bf-443d-8a83-7316b3ca1e48",
   "metadata": {},
   "source": [
    "# _Skin Cancer - Classification Project_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba71b6be-415c-4751-ae77-1e52da1516f8",
   "metadata": {},
   "source": [
    "_Bu projede deri kanserini algılayan bir **CNN modeli** geliştireceğiz. Modeli kaydedip Streamlit uygulamasıa çevireceğiz ve Hugginface de çalışır hale getireceğiz._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e9b986-81c4-4d27-812f-b902f496e46b",
   "metadata": {},
   "source": [
    "### _İmport_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c8a5f52-8df3-4bcc-ad39-01bc5f6fb2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenCV kütüphanesini import ediyoruz, görüntü işleme ve video/frame işlemleri için kullanılır\n",
    "import cv2\n",
    "\n",
    "# Pandas kütüphanesini import ediyoruz, veri analizi ve tablo şeklinde veri yönetimi için kullanılır\n",
    "import pandas as pd\n",
    "\n",
    "# NumPy kütüphanesini import ediyoruz, sayısal hesaplamalar ve matris işlemleri için kullanılır\n",
    "import numpy as np\n",
    "\n",
    "# scikit-learn kütüphanesinden train_test_split fonksiyonunu import ediyoruz,\n",
    "# veriyi eğitim ve test setlerine ayırmak için kullanılır\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Keras kütüphanesinden gerekli modülleri import ediyoruz\n",
    "# Sequential: katman katman model oluşturmak için\n",
    "# Conv2D: 2D evrişim katmanı (görüntülerde özellik çıkarımı için)\n",
    "# Dense: tam bağlantılı katman (sınıflandırma veya regresyon için)\n",
    "# Flatten: çok boyutlu veriyi tek boyuta indirger\n",
    "# Input: modelin giriş katmanı\n",
    "# MaxPooling2D: evrişim katmanından sonra boyut küçültmek için max pooling uygular\n",
    "# Dropout: aşırı öğrenmeyi (overfitting) önlemek için rastgele nöronları kapatır\n",
    "# BatchNormalization: modelin daha hızlı ve stabil öğrenmesini sağlar\n",
    "# Reshape: verinin şeklini değiştirmek için\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Dense, Flatten, Input, MaxPooling2D, Dropout, BatchNormalization, Reshape\n",
    "\n",
    "# İşletim sistemi ile ilgili işlemler yapmak için os modülünü import ediyoruz\n",
    "# Örneğin dosya/dizin kontrolleri, dosya yolları oluşturma gibi\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57505b15-cdc9-4b44-8cfd-b179a8216c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python'da uyarı mesajlarını yönetmek için warnings modülünü import ediyoruz\n",
    "import warnings\n",
    "\n",
    "# Tüm uyarı mesajlarını görmezden gelmek için filterwarnings ile 'ignore' ayarını yapıyoruz\n",
    "# Bu sayede ekranda gereksiz uyarılar görünmez ve kod çıktısı daha temiz olur\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edeeb7b-5514-4d24-8288-6092ef122329",
   "metadata": {},
   "source": [
    "### _Eda_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37965a83-2a39-4122-8383-1df4f7ab370d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sınıf etiketlerini bir liste halinde tanımlıyoruz\n",
    "# 'Cancer' -> Kanserli örnekler\n",
    "# 'Non_Cancer' -> Kanserli olmayan örnekler\n",
    "labels = ['Cancer', 'Non_Cancer']\n",
    "\n",
    "# Görüntülerin bulunduğu ana dizin yolunu belirtiyoruz\n",
    "# Bu klasör içinde 'Cancer' ve 'Non_Cancer' alt klasörleri olabilir\n",
    "img_path = 'Skin_Data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6bb28dc-1af8-4e79-a923-e6248066b65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97d8a155-c8b1-485f-b7f9-eaa690fd18d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boş bir liste oluşturuyoruz; görüntülerin dosya yollarını buraya ekleyeceğiz\n",
    "img_list = []\n",
    "\n",
    "# Boş bir liste oluşturuyoruz; her görüntüye karşılık gelen etiketi buraya ekleyeceğiz\n",
    "label_list = []\n",
    "\n",
    "# labels listesindeki her sınıf (ör. 'Cancer' ve 'Non_Cancer') için döngü\n",
    "for label in labels:\n",
    "    \n",
    "    # Her sınıfın klasöründeki tüm dosyaları listele\n",
    "    for img_file in os.listdir(img_path + label):\n",
    "        \n",
    "        # Görüntü dosyasının tam yolunu oluştur ve img_list'e ekle\n",
    "        img_list.append(img_path + label + \"/\" + img_file)\n",
    "        \n",
    "        # Görüntünün ait olduğu sınıf etiketini label_list'e ekle\n",
    "        label_list.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4427a98-189d-4875-903b-85e2d4642732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_list ve label_list listelerini kullanarak bir DataFrame oluşturuyoruz\n",
    "# DataFrame, tablo şeklinde veri tutmamızı sağlar (sütunlar: 'img' ve 'label')\n",
    "df = pd.DataFrame({'img': img_list,  # 'img' sütunu: görüntü dosya yolları\n",
    "                   'label': label_list})  # 'label' sütunu: her görüntünün sınıf etiketi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c864a66d-f859-4bb8-91ce-cd37a3e7164a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Skin_Data/Cancer/1007-1.jpg</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Skin_Data/Cancer/1010-01.JPG</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Skin_Data/Cancer/1012-2.JPG</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Skin_Data/Cancer/1031-1.jpg</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Skin_Data/Cancer/1051-3(94).jpg</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>Skin_Data/Non_Cancer/953-1.JPG</td>\n",
       "      <td>Non_Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>Skin_Data/Non_Cancer/954-3.JPG</td>\n",
       "      <td>Non_Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>Skin_Data/Non_Cancer/955.JPG</td>\n",
       "      <td>Non_Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>Skin_Data/Non_Cancer/984.JPG</td>\n",
       "      <td>Non_Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>Skin_Data/Non_Cancer/986-1.JPG</td>\n",
       "      <td>Non_Cancer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>288 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 img       label\n",
       "0        Skin_Data/Cancer/1007-1.jpg      Cancer\n",
       "1       Skin_Data/Cancer/1010-01.JPG      Cancer\n",
       "2        Skin_Data/Cancer/1012-2.JPG      Cancer\n",
       "3        Skin_Data/Cancer/1031-1.jpg      Cancer\n",
       "4    Skin_Data/Cancer/1051-3(94).jpg      Cancer\n",
       "..                               ...         ...\n",
       "283   Skin_Data/Non_Cancer/953-1.JPG  Non_Cancer\n",
       "284   Skin_Data/Non_Cancer/954-3.JPG  Non_Cancer\n",
       "285     Skin_Data/Non_Cancer/955.JPG  Non_Cancer\n",
       "286     Skin_Data/Non_Cancer/984.JPG  Non_Cancer\n",
       "287   Skin_Data/Non_Cancer/986-1.JPG  Non_Cancer\n",
       "\n",
       "[288 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e4c58de-7e2f-4b4e-a2d7-bbe78201f501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cancer = 1\n",
    "# non_cancer = 0 yazdırmak istersek;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57ed6866-df77-4e96-a7e0-9831503483cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sınıf isimlerini sayısal değerlere eşleyecek bir sözlük oluşturuyoruz\n",
    "# 'Cancer' -> 1, 'Non_Cancer' -> 0\n",
    "d = {'Cancer': 1, 'Non_Cancer': 0}\n",
    "\n",
    "# DataFrame'deki 'label' sütununu sayısal değerlere çeviriyoruz\n",
    "# map fonksiyonu, her etiketi sözlükteki karşılığı ile değiştirir\n",
    "df['label_encoded'] = df['label'].map(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8ac82ef-c853-42f4-8715-d651a1622292",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img</th>\n",
       "      <th>label</th>\n",
       "      <th>label_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Skin_Data/Cancer/1007-1.jpg</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Skin_Data/Cancer/1010-01.JPG</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Skin_Data/Cancer/1012-2.JPG</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Skin_Data/Cancer/1031-1.jpg</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Skin_Data/Cancer/1051-3(94).jpg</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>Skin_Data/Non_Cancer/953-1.JPG</td>\n",
       "      <td>Non_Cancer</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>Skin_Data/Non_Cancer/954-3.JPG</td>\n",
       "      <td>Non_Cancer</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>Skin_Data/Non_Cancer/955.JPG</td>\n",
       "      <td>Non_Cancer</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>Skin_Data/Non_Cancer/984.JPG</td>\n",
       "      <td>Non_Cancer</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>Skin_Data/Non_Cancer/986-1.JPG</td>\n",
       "      <td>Non_Cancer</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>288 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 img       label  label_encoded\n",
       "0        Skin_Data/Cancer/1007-1.jpg      Cancer              1\n",
       "1       Skin_Data/Cancer/1010-01.JPG      Cancer              1\n",
       "2        Skin_Data/Cancer/1012-2.JPG      Cancer              1\n",
       "3        Skin_Data/Cancer/1031-1.jpg      Cancer              1\n",
       "4    Skin_Data/Cancer/1051-3(94).jpg      Cancer              1\n",
       "..                               ...         ...            ...\n",
       "283   Skin_Data/Non_Cancer/953-1.JPG  Non_Cancer              0\n",
       "284   Skin_Data/Non_Cancer/954-3.JPG  Non_Cancer              0\n",
       "285     Skin_Data/Non_Cancer/955.JPG  Non_Cancer              0\n",
       "286     Skin_Data/Non_Cancer/984.JPG  Non_Cancer              0\n",
       "287   Skin_Data/Non_Cancer/986-1.JPG  Non_Cancer              0\n",
       "\n",
       "[288 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df\n",
    "\n",
    "#Oluşturduğumuz dataframein tamamını görüntüleyebiliriz."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf3c494-bddb-45e0-b37d-ecb93bb8155c",
   "metadata": {},
   "source": [
    "### _Classification_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51cad6ff-321b-4dd7-8538-d091c0058cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boş bir liste oluşturuyoruz; işlenmiş görüntüleri buraya ekleyeceğiz\n",
    "x = []  \n",
    "\n",
    "# DataFrame'deki tüm görüntü dosya yolları üzerinde döngü\n",
    "for img in df['img']:\n",
    "    \n",
    "    # Görüntüyü OpenCV ile oku\n",
    "    img = cv2.imread(str(img))\n",
    "    \n",
    "    # Görüntüyü 170x170 boyutuna yeniden boyutlandır\n",
    "    # Not: ResNet transfer learning kullanacağımız için 170x170 girdik\n",
    "    # Ama başka projelerde yeterli RAM varsa istediğimiz başka boyutu da kullanabiliriz\n",
    "    img = cv2.resize(img, (170, 170))\n",
    "    \n",
    "    # Piksel değerlerini normalize et (0-1 aralığına getir)\n",
    "    img = img / 255.0\n",
    "    \n",
    "    # İşlenmiş görüntüyü listeye ekle\n",
    "    x.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44185bd-e6f9-4296-9704-bfb849b67172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eğer üstteki kod çalışmazsa aşağıdakini dene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f53eeb3-2c5c-4bf5-a30e-4348a62a46c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "x = []\n",
    "\n",
    "for img in tqdm(df['img']):\n",
    "\n",
    "    # Görüntüyü oku\n",
    "    img = cv2.imread(str(img))\n",
    "\n",
    "    if img is None:\n",
    "        print(\"Bozuk veya okunamayan dosya:\", img)\n",
    "        continue  # bu dosyayı atla\n",
    "\n",
    "    # 170x170 boyutuna yeniden boyutlandır\n",
    "    img = cv2.resize(img, (170, 170))\n",
    "\n",
    "    # Piksel değerlerini normalize et\n",
    "    img = img / 255.0\n",
    "\n",
    "    # İşlenmiş görüntüyü listeye ekle\n",
    "    x.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ded8e909-d2af-4a44-9e84-3e8060910ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x listesini NumPy dizisine çeviriyoruz\n",
    "# Çünkü makine öğrenmesi ve derin öğrenme kütüphaneleri genellikle NumPy dizileri ile çalışır\n",
    "x = np.array(x)  # Artık x, modelin anlayacağı şekilde çok boyutlu bir dizi (array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb9379bd-54ea-4415-9ddf-2ddd2ac16f75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(288, 170, 170, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d5af0846-686d-4097-b8b4-584fb9858f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame'den sadece 'label_encoded' sütununu seçiyoruz\n",
    "# Bu sütun, her görüntünün sayısal sınıf etiketini (0 veya 1) içeriyor\n",
    "y = df[['label_encoded']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7b65d1b4-3cf2-4373-8541-0e896377b360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veriyi eğitim ve test setlerine ayırıyoruz\n",
    "# x → görüntü verileri (girdi)\n",
    "# y → etiketler (çıktı)\n",
    "# test_size=0.20 → verinin %20'si test seti, %80'i eğitim seti olacak\n",
    "# random_state=42 → rastgele bölme işleminin tekrarlanabilir olmasını sağlar\n",
    "#                  42 sadece farklı bir sabit sayı, aynı sayıyı her kullanışta aynı bölme elde edilir\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "30afd7b9-1dbc-4619-a20a-e6acf2f06a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eğitim etiketlerini NumPy dizisine çeviriyoruz ve veri tipini int32 olarak belirliyoruz\n",
    "y_train = np.array(y_train, dtype=np.int32)\n",
    "\n",
    "# Test etiketlerini NumPy dizisine çeviriyoruz ve veri tipini int32 olarak belirliyoruz\n",
    "y_test = np.array(y_test, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ab95e53-0277-4c19-aed8-196c73f5b9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequential model oluşturuyoruz, katman katman model ekleyebileceğiz\n",
    "model = Sequential()\n",
    "\n",
    "# Modelin giriş katmanını tanımlıyoruz\n",
    "# Girdi boyutu: 170x170 piksel, 3 renk kanalı (RGB)\n",
    "model.add(Input(shape=(170, 170, 3)))\n",
    "\n",
    "# 1. Convolution (evrişim) katmanı\n",
    "# 32 filtre, 3x3 boyutunda, aktivasyon fonksiyonu ReLU\n",
    "# Görüntüden özellikler çıkarır\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
    "\n",
    "# 1. MaxPooling katmanı\n",
    "# 2x2 boyutunda, uzaysal boyutları küçültür ve hesaplamayı azaltır\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# 2. Convolution katmanı\n",
    "# 64 filtre, 3x3 boyutunda, aktivasyon fonksiyonu ReLU\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "\n",
    "# 2. MaxPooling katmanı\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Flatten katmanı\n",
    "# Çok boyutlu veriyi tek boyuta indirger, Dense katmanına girdi olarak verir\n",
    "model.add(Flatten())\n",
    "\n",
    "# Tam bağlantılı (Dense) katman\n",
    "# 128 nöron, ReLU aktivasyonu\n",
    "# Görüntüden çıkarılan özellikleri birleştirir ve öğrenir\n",
    "model.add(Dense(128, activation='relu'))\n",
    "\n",
    "# Çıkış katmanı\n",
    "# 1 nöron, sigmoid aktivasyonu\n",
    "# Binary classification için 0-1 arasında tahmin verir\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Modeli derliyoruz\n",
    "# optimizer='adam' → ağırlıkları güncellemek için Adam optimizasyonu\n",
    "# loss='binary_crossentropy' → binary sınıflandırma için uygun kayıp fonksiyonu\n",
    "# metrics=['accuracy'] → eğitimi izlerken doğruluk metriğini hesaplar\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "107b6db3-9033-437d-b603-75aeeb4e97ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 263ms/step - accuracy: 0.6174 - loss: 1.3681 - val_accuracy: 0.7414 - val_loss: 0.7490\n",
      "Epoch 2/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 217ms/step - accuracy: 0.7043 - loss: 0.6728 - val_accuracy: 0.7759 - val_loss: 0.6040\n",
      "Epoch 3/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 222ms/step - accuracy: 0.7174 - loss: 0.5826 - val_accuracy: 0.7931 - val_loss: 0.5361\n",
      "Epoch 4/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 219ms/step - accuracy: 0.8000 - loss: 0.4828 - val_accuracy: 0.7414 - val_loss: 0.6805\n",
      "Epoch 5/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 218ms/step - accuracy: 0.7783 - loss: 0.4863 - val_accuracy: 0.8276 - val_loss: 0.3771\n",
      "Epoch 6/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 220ms/step - accuracy: 0.8087 - loss: 0.4160 - val_accuracy: 0.8621 - val_loss: 0.3735\n",
      "Epoch 7/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 221ms/step - accuracy: 0.8435 - loss: 0.3326 - val_accuracy: 0.8103 - val_loss: 0.4026\n",
      "Epoch 8/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 223ms/step - accuracy: 0.8696 - loss: 0.2885 - val_accuracy: 0.8621 - val_loss: 0.3736\n",
      "Epoch 9/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 219ms/step - accuracy: 0.8957 - loss: 0.2582 - val_accuracy: 0.8448 - val_loss: 0.4082\n",
      "Epoch 10/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 224ms/step - accuracy: 0.9130 - loss: 0.2153 - val_accuracy: 0.8103 - val_loss: 0.5547\n",
      "Epoch 11/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 226ms/step - accuracy: 0.8826 - loss: 0.2825 - val_accuracy: 0.8103 - val_loss: 0.4274\n",
      "Epoch 12/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 219ms/step - accuracy: 0.9391 - loss: 0.1924 - val_accuracy: 0.8966 - val_loss: 0.2412\n",
      "Epoch 13/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 216ms/step - accuracy: 0.9043 - loss: 0.2002 - val_accuracy: 0.5345 - val_loss: 1.1331\n",
      "Epoch 14/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 217ms/step - accuracy: 0.8478 - loss: 0.2874 - val_accuracy: 0.8793 - val_loss: 0.2767\n",
      "Epoch 15/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 220ms/step - accuracy: 0.9435 - loss: 0.1691 - val_accuracy: 0.8793 - val_loss: 0.2827\n",
      "Epoch 16/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 223ms/step - accuracy: 0.9696 - loss: 0.1062 - val_accuracy: 0.8793 - val_loss: 0.3401\n",
      "Epoch 17/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 219ms/step - accuracy: 0.9696 - loss: 0.0851 - val_accuracy: 0.6724 - val_loss: 0.8984\n",
      "Epoch 18/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 218ms/step - accuracy: 0.9609 - loss: 0.1093 - val_accuracy: 0.9310 - val_loss: 0.2496\n",
      "Epoch 19/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 216ms/step - accuracy: 0.9609 - loss: 0.1065 - val_accuracy: 0.8276 - val_loss: 0.3830\n",
      "Epoch 20/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 218ms/step - accuracy: 0.9783 - loss: 0.0714 - val_accuracy: 0.8621 - val_loss: 0.3071\n"
     ]
    }
   ],
   "source": [
    "# Modeli eğitim verisiyle eğitiyoruz\n",
    "history = model.fit(\n",
    "    x_train,              # Girdi verileri (görüntüler)\n",
    "    y_train,              # Hedef etiketler (0 veya 1)\n",
    "    validation_data=(x_test, y_test),  # Her epoch sonunda test verisi ile doğrulama\n",
    "    epochs=20,            # Modelin tüm eğitim verisi üzerinden 20 kez geçmesi\n",
    "    verbose=1             # Eğitim sırasında ilerleme çubuğunu göster\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1dfeb1-230d-4912-be13-e53b8ee4c6b2",
   "metadata": {},
   "source": [
    "### _Save the Model_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "db0314d8-e7f7-456b-92c3-88fb3b159171",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.save('skin_cancer_model.keras') # huggine kaydetmek istiyorsam .h5 ile kaydetmem lazım"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5b9d51-fe9b-49e4-bbf3-92ecf582d3a4",
   "metadata": {},
   "source": [
    "### _Transfer Learning_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b55bdba-7dac-42e4-8219-9542d2e054fe",
   "metadata": {},
   "source": [
    "_Akıllı insan aklını kullanandır. Daha da akıllı insan başkalarınında aklını kullanandır_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43dc98f2-e480-49e0-beb2-5740b8d70754",
   "metadata": {},
   "source": [
    "#### _İmport_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d91a22d7-ca29-451e-af0d-c808c2675722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras'ın hazır transfer learning modellerini import ediyoruz\n",
    "# VGG16 ve ResNet50, önceden ImageNet veri setinde eğitilmiş derin CNN modelleridir\n",
    "from tensorflow.keras.applications import VGG16, ResNet50\n",
    "\n",
    "# Görüntü verilerini işlemek ve artırmak (augmentation) için ImageDataGenerator sınıfını import ediyoruz\n",
    "# Örneğin: döndürme, yakınlaştırma, kaydırma gibi işlemlerle eğitim verisini zenginleştirmek için kullanılır\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd9aeca-b37e-4d4a-aaa6-e4271e77d868",
   "metadata": {},
   "source": [
    "#### _İmport Another Model - Classification_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aa2cf10b-d467-4139-8411-b8408ef021e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 232 images belonging to 2 classes.\n",
      "Found 56 images belonging to 2 classes.\n",
      "Epoch 1/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 3s/step - accuracy: 0.5819 - loss: 4.9801 - val_accuracy: 0.7143 - val_loss: 2.9046\n",
      "Epoch 2/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 3s/step - accuracy: 0.6897 - loss: 2.1570 - val_accuracy: 0.2857 - val_loss: 1.5291\n",
      "Epoch 3/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 3s/step - accuracy: 0.7198 - loss: 0.7894 - val_accuracy: 0.8571 - val_loss: 0.3875\n",
      "Epoch 4/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 3s/step - accuracy: 0.7974 - loss: 0.4272 - val_accuracy: 0.7500 - val_loss: 0.7630\n",
      "Epoch 5/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 3s/step - accuracy: 0.8621 - loss: 0.3257 - val_accuracy: 0.8393 - val_loss: 0.3579\n",
      "Epoch 6/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 3s/step - accuracy: 0.8966 - loss: 0.2025 - val_accuracy: 0.8571 - val_loss: 0.4193\n",
      "Epoch 7/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 3s/step - accuracy: 0.9483 - loss: 0.1546 - val_accuracy: 0.8393 - val_loss: 0.3899\n",
      "Epoch 8/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.9483 - loss: 0.1461 - val_accuracy: 0.8571 - val_loss: 0.3515\n",
      "Epoch 9/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.9569 - loss: 0.1197 - val_accuracy: 0.8571 - val_loss: 0.3422\n",
      "Epoch 10/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3s/step - accuracy: 0.9698 - loss: 0.1100 - val_accuracy: 0.8214 - val_loss: 0.3298\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1b369f27250>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ana veri klasörünün yolunu belirliyoruz\n",
    "data_dir = 'Skin_Data'\n",
    "\n",
    "# Modelin girdi boyutunu belirliyoruz (224x224 piksel)\n",
    "img_width, img_heigth = 224, 224\n",
    "\n",
    "# Eğitim verisi için ImageDataGenerator oluşturuyoruz\n",
    "# rescale=1/255 → piksel değerlerini 0-1 aralığına normalize ediyor\n",
    "# validation_split=0.20 → verinin %20'sini doğrulama için ayırıyor\n",
    "train_datagen = ImageDataGenerator(rescale=1/255, validation_split=0.20)\n",
    "\n",
    "# Eğitim verilerini klasörden okuyup artırma ve hazırlama\n",
    "train_datagenerator = train_datagen.flow_from_directory(\n",
    "    directory=data_dir,              # Ana veri klasörü\n",
    "    target_size=(img_width,img_heigth),  # Görüntüleri 224x224 boyutuna getir\n",
    "    class_mode='binary',             # Binary sınıflandırma\n",
    "    subset='training'                # Eğitim verisi olarak ayır\n",
    ")\n",
    "\n",
    "# Test/verifikasyon verilerini hazırlıyoruz\n",
    "test_datagen = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "# Doğrulama verilerini klasörden alıyoruz\n",
    "test_datagenerator = train_datagen.flow_from_directory(\n",
    "    directory=data_dir,\n",
    "    target_size=(img_width,img_heigth),\n",
    "    class_mode='binary',\n",
    "    subset='validation'              # Doğrulama seti\n",
    ")\n",
    "\n",
    "# Önceden eğitilmiş VGG16 modelini yükle\n",
    "# weights='imagenet' → ImageNet üzerinde önceden eğitilmiş ağırlıklar\n",
    "# include_top=False → son sınıflandırma katmanını dahil etme (kendi katmanlarımızı ekleyeceğiz)\n",
    "base_model = VGG16(weights='imagenet', input_shape=(img_width,img_heigth,3), include_top=False)\n",
    "\n",
    "# Yeni bir Sequential model oluşturuyoruz\n",
    "model = Sequential()\n",
    "model.add(base_model)  # Önceden eğitilmiş VGG16 tabanını ekliyoruz\n",
    "\n",
    "# VGG16 tabanındaki tüm katmanları donduruyoruz, yani eğitim sırasında güncellenmeyecek\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Kendi üst katmanlarımızı ekliyoruz\n",
    "model.add(Flatten())            # Çok boyutlu özellik haritasını tek boyuta çevir\n",
    "model.add(Dense(1024, activation='relu'))  # Fully connected katman, öğrenilen özellikleri birleştir\n",
    "model.add(Dense(1, activation='sigmoid'))  # Çıkış katmanı, binary sınıflandırma\n",
    "\n",
    "# Modeli derliyoruz\n",
    "model.compile(\n",
    "    optimizer='adam',                 # Ağırlıkları güncellemek için Adam optimizasyonu\n",
    "    loss='binary_crossentropy',       # Binary sınıflandırma kayıp fonksiyonu\n",
    "    metrics=['accuracy']              # Eğitim ve doğrulama sırasında doğruluk metriğini takip et\n",
    ")\n",
    "\n",
    "# Modeli eğitim verisiyle eğitiyoruz ve doğrulama verisiyle test ediyoruz\n",
    "# epochs=10 → veri üzerinden 10 kez geçiyoruz\n",
    "model.fit(\n",
    "    train_datagenerator,\n",
    "    epochs=10,\n",
    "    validation_data=test_datagenerator\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2e20c9-871b-491c-beb3-5b6989f3156c",
   "metadata": {},
   "source": [
    "#### _Save the Transfer Learning Model_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "64384d0a-a12b-46b5-a63a-8a0ebbdd6cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('skin_cancer.TL.h5') # hugginface de bu uzantıyı kullanabiliyorum; h5\n",
    "model.save('skin_cancer.TL.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
