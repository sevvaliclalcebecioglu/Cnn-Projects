{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZpexXbX2XxYE"
   },
   "source": [
    "# *Fruit and Vegetables- CNN Model*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9zMzITOdX4T8"
   },
   "source": [
    "*Bu projede, görüntüleri analiz ederek türüne göre meyve ya da sebze diye sınıflandıran bir CNN Modeli geliştireceğiz. Modeli kaydedip Streamlit uygulamasına çevireceğiz ve HugginFace de çalışır hale getireceğiz.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IxgpKmpVX_cE"
   },
   "source": [
    "### *import Libraries*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Dq38MzR1XpBy"
   },
   "outputs": [],
   "source": [
    "import os                  # Dosya ve dizin işlemleri için\n",
    "import random              # Rastgele seçimler yapmak için\n",
    "import warnings            # Uyarı mesajlarını yönetmek için\n",
    "warnings.filterwarnings('ignore') # Tüm uyarı mesajlarını görmezden gelmek için filterwarnings ile 'ignore' ayarını yapıyoruz\n",
    "\n",
    "import numpy as np         # Sayısal hesaplamalar ve matris işlemleri\n",
    "import pandas as pd        # Veri analizi ve tablo işlemleri\n",
    "import cv2                 # Görüntü işleme ve video/frame işlemleri\n",
    "import kagglehub           # Kaggle veri setlerini kolayca çekmek için\n",
    "import random\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split  # Veriyi eğitim/test setlerine ayırmak için\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import Model            # Keras Functional API model tanımı\n",
    "from tensorflow.keras.layers import Flatten, Dense   # Katmanlar: Flatten ve tam bağlantılı Dense\n",
    "from tensorflow.keras.applications import VGG16      # Önceden eğitilmiş VGG16 modeli\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qI0kCbxhYFir"
   },
   "source": [
    "### *İmport Data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yyXW-KQWYErk",
    "outputId": "54b3a07f-b55f-4f4b-c392-0cbe2e166c26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/kritikseth/fruit-and-vegetable-image-recognition?dataset_version_number=8...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1.98G/1.98G [01:32<00:00, 23.1MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /root/.cache/kagglehub/datasets/kritikseth/fruit-and-vegetable-image-recognition/versions/8\n"
     ]
    }
   ],
   "source": [
    "# Görüntülerin bulunduğu ana dizin yolunu belirtiyoruz\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"kritikseth/fruit-and-vegetable-image-recognition\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9dhR3hFuY0vy",
    "outputId": "cadb5e24-1948-4f7c-d5ac-7845ba3f578c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['validation', 'train', 'test']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_path = os.path.join(path)\n",
    "os.listdir(img_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AxKqNSxVYtAs"
   },
   "source": [
    "### *CNN with Transfer Learning*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UXbCNFscYZCq",
    "outputId": "3c27e9dc-1a06-42b4-c5aa-a39b938638aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2510 images belonging to 36 classes.\n",
      "Found 63 images belonging to 36 classes.\n"
     ]
    }
   ],
   "source": [
    "# Resim boyutlarını ayarlayın\n",
    "img_width, img_height = 224, 224\n",
    "\n",
    "# Veri dizinini tanımlayın\n",
    "img_path = kagglehub.dataset_download(\"kritikseth/fruit-and-vegetable-image-recognition\")   # Burada doğru dizini belirtmelisiniz\n",
    "\n",
    "# Eğitim ve doğrulama veri dizinleri\n",
    "train_dir = os.path.join(img_path, \"train\")  # Eğitim verisi dizini\n",
    "validation_dir = os.path.join(img_path, \"validation\")  # Doğrulama verisi dizini\n",
    "\n",
    "# Eğitim ve doğrulama verilerini hazırlamak için ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "\n",
    "# Eğitim veri kümesini yükleyin\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,  # Eğitim verisi dizini\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',  # Çoklu sınıf problemi\n",
    "    subset='training'  # Eğitim verisi\n",
    ")\n",
    "\n",
    "# Doğrulama veri kümesini yükleyin\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    validation_dir,  # Doğrulama verisi dizini\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',  # Çoklu sınıf problemi\n",
    "    subset='validation'  # Doğrulama verisi\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v7ymLGgOYwoE",
    "outputId": "3f05dc5d-ba4c-4b13-f188-e5e81a58327b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m58889256/58889256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\n",
      "Epoch 1/10\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 1s/step - accuracy: 0.1954 - loss: 6.0987 - val_accuracy: 0.8889 - val_loss: 0.5973\n",
      "Epoch 2/10\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 798ms/step - accuracy: 0.8095 - loss: 0.7462 - val_accuracy: 0.9048 - val_loss: 0.3416\n",
      "Epoch 3/10\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 790ms/step - accuracy: 0.9448 - loss: 0.2554 - val_accuracy: 0.9048 - val_loss: 0.2889\n",
      "Epoch 4/10\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 806ms/step - accuracy: 0.9867 - loss: 0.1035 - val_accuracy: 0.9365 - val_loss: 0.2165\n",
      "Epoch 5/10\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 813ms/step - accuracy: 0.9898 - loss: 0.0682 - val_accuracy: 0.9524 - val_loss: 0.1595\n",
      "Epoch 6/10\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 804ms/step - accuracy: 0.9909 - loss: 0.0576 - val_accuracy: 0.9524 - val_loss: 0.1586\n",
      "Epoch 7/10\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 786ms/step - accuracy: 0.9933 - loss: 0.0372 - val_accuracy: 0.9524 - val_loss: 0.1457\n",
      "Epoch 8/10\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 810ms/step - accuracy: 0.9852 - loss: 0.0608 - val_accuracy: 0.9524 - val_loss: 0.1350\n",
      "Epoch 9/10\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 801ms/step - accuracy: 0.9887 - loss: 0.0586 - val_accuracy: 0.9524 - val_loss: 0.1368\n",
      "Epoch 10/10\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 799ms/step - accuracy: 0.9940 - loss: 0.0336 - val_accuracy: 0.9206 - val_loss: 0.2346\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7d7e6fe20fe0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# VGG16 modelini yükleyin (ImageNet'ten önceden eğitilmiş)\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(img_width, img_height, 3))\n",
    "base_model.trainable = False  # Önceden eğitilmiş katmanları dondur\n",
    "\n",
    "# Üst katmanları ekleyin\n",
    "x = base_model.output\n",
    "x = Flatten()(x)  # Çıkışı düzleştir\n",
    "x = Dense(1024, activation='relu')(x)  # Tam bağlantılı katman\n",
    "predictions = Dense(len(train_generator.class_indices), activation='softmax')(x)  # Sınıf sayısı kadar çıktı\n",
    "\n",
    "# Modeli tanımlayın (Functional API kullanılarak)\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Modeli derleyin\n",
    "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Modeli eğitin\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=validation_generator\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JPsIR21KDtCl"
   },
   "source": [
    "### *Save the Model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "E5yGG5szB9u1"
   },
   "outputs": [],
   "source": [
    "# Modeli kaydedin\n",
    "model.save('fruits_and_vegetables_TL.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fbjFSqDvCPtX"
   },
   "source": [
    "*Bu projede meyve ve sebze görüntülerini analiz ederek türlerini sınıflandıran bir CNN Modeli geliştirdik. Datayı kaggle üzerinden çektik. Kendi datamızı önceden eğitilmiş VGG16 modeli ile birleştirip geliştirdik. %99.46 başarı elde ettik.*"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "runtime_attributes": {
    "runtime_version": "2025.10"
   }
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
