{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_9-UXudTx22P"
   },
   "source": [
    "# *Rice - Classification Project*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q3Pv9SUnx8gw"
   },
   "source": [
    "*Bu projede pirinç türlerini algılayan bir **CNN Modeli** geliştireceğiz. Modeli kaydedip Streamlit uygulamasına çevireceğiz ve HugginFace de çalışır hale getireceğiz.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t94q3O-jyG_4"
   },
   "source": [
    "### *İmport Libraries*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "A_evLn7hx-sg"
   },
   "outputs": [],
   "source": [
    "import os                  # Dosya ve dizin işlemleri için\n",
    "import random              # Rastgele seçimler yapmak için\n",
    "import warnings            # Uyarı mesajlarını yönetmek için\n",
    "warnings.filterwarnings('ignore') # Tüm uyarı mesajlarını görmezden gelmek için filterwarnings ile 'ignore' ayarını yapıyoruz\n",
    "\n",
    "import numpy as np         # Sayısal hesaplamalar ve matris işlemleri\n",
    "import pandas as pd        # Veri analizi ve tablo işlemleri\n",
    "import cv2                 # Görüntü işleme ve video/frame işlemleri\n",
    "import kagglehub           # Kaggle veri setlerini kolayca çekmek için\n",
    "\n",
    "from sklearn.model_selection import train_test_split  # Veriyi eğitim/test setlerine ayırmak için\n",
    "\n",
    "from tensorflow.keras.models import Model            # Keras Functional API model tanımı\n",
    "from tensorflow.keras.layers import Flatten, Dense   # Katmanlar: Flatten ve tam bağlantılı Dense\n",
    "from tensorflow.keras.applications import VGG16      # Önceden eğitilmiş VGG16 modeli\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator  # Görüntü artırma ve ön işleme\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HOITDbU9yNPQ"
   },
   "source": [
    "### *İmport Data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lEAtmKJfyPHI",
    "outputId": "12641d6e-f09e-4590-a822-316e96f44bae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/muratkokludataset/rice-image-dataset?dataset_version_number=1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 219M/219M [00:10<00:00, 21.6MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /root/.cache/kagglehub/datasets/muratkokludataset/rice-image-dataset/versions/1\n"
     ]
    }
   ],
   "source": [
    "# Sınıf etiketlerini bir liste halinde tanımlıyoruz\n",
    "# 'Arborio' -> Arborio örnekleri\n",
    "# 'Basmati' -> Basmati örnekleri\n",
    "# 'Ipsala' -> Ipsala örnekleri\n",
    "# 'Jasmine' -> Jasmine örnekleri\n",
    "# 'Karacadag' -> Karacadag örnekleri\n",
    "labels = ['Arborio', 'Basmati', 'Ipsala', 'Jasmine', 'Karacadag']\n",
    "\n",
    "# Görüntülerin bulunduğu ana dizin yolunu belirtiyoruz\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"muratkokludataset/rice-image-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wcx66eMFkX1O",
    "outputId": "894e6baa-37f3-4dd1-d6e7-e7ef8cb0050b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ipsala',\n",
       " 'Arborio',\n",
       " 'Jasmine',\n",
       " 'Karacadag',\n",
       " 'Basmati',\n",
       " 'Rice_Citation_Request.txt']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_path = os.path.join(path, \"Rice_Image_Dataset/\")\n",
    "os.listdir(img_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AhxL6JF95H9X"
   },
   "source": [
    "### *CNN with Transfer Learning*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wxEV7XIo5UFa",
    "outputId": "2f354857-a6fe-48e7-b248-eccf8a5e11d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 60000 images belonging to 5 classes.\n",
      "Found 15000 images belonging to 5 classes.\n",
      "Epoch 1/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m409s\u001b[0m 217ms/step - accuracy: 0.9395 - loss: 0.4100 - val_accuracy: 0.9780 - val_loss: 0.0680\n",
      "Epoch 2/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m404s\u001b[0m 215ms/step - accuracy: 0.9828 - loss: 0.0491 - val_accuracy: 0.9911 - val_loss: 0.0283\n",
      "Epoch 3/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m404s\u001b[0m 215ms/step - accuracy: 0.9888 - loss: 0.0332 - val_accuracy: 0.9925 - val_loss: 0.0234\n",
      "Epoch 4/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m404s\u001b[0m 216ms/step - accuracy: 0.9920 - loss: 0.0244 - val_accuracy: 0.9901 - val_loss: 0.0312\n",
      "Epoch 5/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m404s\u001b[0m 215ms/step - accuracy: 0.9927 - loss: 0.0223 - val_accuracy: 0.9961 - val_loss: 0.0143\n",
      "Epoch 6/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m404s\u001b[0m 216ms/step - accuracy: 0.9935 - loss: 0.0198 - val_accuracy: 0.9952 - val_loss: 0.0172\n",
      "Epoch 7/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m404s\u001b[0m 216ms/step - accuracy: 0.9947 - loss: 0.0154 - val_accuracy: 0.9907 - val_loss: 0.0314\n",
      "Epoch 8/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m403s\u001b[0m 215ms/step - accuracy: 0.9949 - loss: 0.0161 - val_accuracy: 0.9963 - val_loss: 0.0128\n",
      "Epoch 9/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m404s\u001b[0m 215ms/step - accuracy: 0.9947 - loss: 0.0158 - val_accuracy: 0.9951 - val_loss: 0.0173\n",
      "Epoch 10/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m404s\u001b[0m 215ms/step - accuracy: 0.9962 - loss: 0.0114 - val_accuracy: 0.9937 - val_loss: 0.0227\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7cab3af11af0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Modelin girdi boyutu\n",
    "img_width, img_height = 224, 224\n",
    "\n",
    "# --- Veri hazırlama ---\n",
    "train_datagen = ImageDataGenerator(rescale=1/255, validation_split=0.20)\n",
    "\n",
    "train_datagenerator = train_datagen.flow_from_directory(\n",
    "    directory=img_path,\n",
    "    target_size=(img_width, img_height),\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "test_datagenerator = train_datagen.flow_from_directory(\n",
    "    directory=img_path,\n",
    "    target_size=(img_width, img_height),\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "# --- Transfer Learning: VGG16 base ---\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(img_width, img_height, 3))\n",
    "base_model.trainable = False  # Tüm katmanları dondur\n",
    "\n",
    "# --- Functional API ile üst katmanlar ---\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "outputs = Dense(5, activation='softmax')(x)  # 5 sınıf\n",
    "\n",
    "# --- Model tanımı ---\n",
    "model = Model(inputs=base_model.input, outputs=outputs)\n",
    "\n",
    "# --- Compile ---\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# --- Eğitim ---\n",
    "model.fit(\n",
    "    train_datagenerator,\n",
    "    epochs=10,\n",
    "    validation_data=test_datagenerator\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ipIMH7x25XZQ"
   },
   "source": [
    "#### *Save the Learning Model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "SSvwwilO5bAS"
   },
   "outputs": [],
   "source": [
    "# --- Kaydet (Keras 3 uyumlu) ---\n",
    "model.save(\"rice_model_TL.keras\")  # Streamlit ve Hugging Face uyumlu\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ddmg66t2u77w"
   },
   "source": [
    "*Bu projede pirinç türlerini algılayan bir CNN Modeli geliştirdik.* <br>\n",
    "*Datayı kaggle üzerinden çektik.* <br>\n",
    "*Kendi datamızı önceden eğitilmiş **VGG16** modeli ile birleştirip geliştirdik.* <br>\n",
    "*%99.66 başarı elde ettik.*"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
